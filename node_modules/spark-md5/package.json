{
  "_args": [
    [
      {
        "raw": "spark-md5@^1.0.0",
        "scope": null,
        "escapedName": "spark-md5",
        "name": "spark-md5",
        "rawSpec": "^1.0.0",
        "spec": ">=1.0.0 <2.0.0",
        "type": "range"
      },
      "/opt/skipper/node_modules/swagger-tools"
    ]
  ],
  "_from": "spark-md5@>=1.0.0 <2.0.0",
  "_id": "spark-md5@1.0.1",
  "_inCache": true,
  "_location": "/spark-md5",
  "_nodeVersion": "4.2.6",
  "_npmOperationalInternal": {
    "host": "packages-6-west.internal.npmjs.com",
    "tmp": "tmp/spark-md5-1.0.1.tgz_1456096562618_0.16418782901018858"
  },
  "_npmUser": {
    "name": "satazor",
    "email": "andremiguelcruz@msn.com"
  },
  "_npmVersion": "2.14.12",
  "_phantomChildren": {},
  "_requested": {
    "raw": "spark-md5@^1.0.0",
    "scope": null,
    "escapedName": "spark-md5",
    "name": "spark-md5",
    "rawSpec": "^1.0.0",
    "spec": ">=1.0.0 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/swagger-tools"
  ],
  "_resolved": "https://registry.npmjs.org/spark-md5/-/spark-md5-1.0.1.tgz",
  "_shasum": "c4b9a8d41cf7b0845423a821824f8dffa0f51b7c",
  "_shrinkwrap": null,
  "_spec": "spark-md5@^1.0.0",
  "_where": "/opt/skipper/node_modules/swagger-tools",
  "author": {
    "name": "AndrÃ© Cruz",
    "email": "andremiguelcruz@msn.com"
  },
  "bugs": {
    "url": "https://github.com/satazor/SparkMD5/issues"
  },
  "dependencies": {},
  "description": "Lightning fast normal and incremental md5 for javascript",
  "devDependencies": {
    "uglify-js": "^2.4.16"
  },
  "directories": {
    "test": "test"
  },
  "dist": {
    "shasum": "c4b9a8d41cf7b0845423a821824f8dffa0f51b7c",
    "tarball": "https://registry.npmjs.org/spark-md5/-/spark-md5-1.0.1.tgz"
  },
  "gitHead": "32e9e52292e0a38c2d22916db49c85d7f16b7d1d",
  "homepage": "https://github.com/satazor/SparkMD5#readme",
  "keywords": [
    "md5",
    "fast",
    "spark",
    "incremental"
  ],
  "license": "WTFPL",
  "main": "spark-md5.js",
  "maintainers": [
    {
      "name": "satazor",
      "email": "andremiguelcruz@msn.com"
    }
  ],
  "name": "spark-md5",
  "optionalDependencies": {},
  "readme": "# SparkMD5\n\nSparkMD5 is a fast md5 implementation of the MD5 algorithm.\nThis script is based in the JKM md5 library which is the [fastest](http://jsperf.com/md5-shootout/7) algorithm around. This is most suitable for browser usage, because `nodejs` version might be faster.\n\nNOTE: Please disable Firebug while performing the test!\n      Firebug consumes a lot of memory and CPU and slows the test by a great margin.\n\n\n**[Demo](http://9px.ir/demo/incremental-md5.html)**\n\n\n## Improvements over the JKM md5 library\n\n * Strings are converted to utf8, like most server side algorithms\n * Fix computation for large amounts of data (overflow)\n * Incremental md5 (see bellow)\n * Support for array buffers (typed arrays)\n * Functionality wrapped in a closure, to avoid global assignments\n * Object oriented library\n * CommonJS (it can be used in node) and AMD integration\n * Code passed through JSHint and JSCS\n\n\nIncremental md5 performs a lot better for hashing large amounts of data, such as\nfiles. One could read files in chunks, using the FileReader & Blob's, and append\neach chunk for md5 hashing while keeping memory usage low. See example bellow.\n\n\n## Usage\n\n### Normal usage\n\n```js\nvar hexHash = SparkMD5.hash('Hi there');        // hex hash\nvar rawHash = SparkMD5.hash('Hi there', true);  // OR raw hash\n```\n\n### Incremental usage\n\n```js\nvar spark = new SparkMD5();\nspark.append('Hi');\nspark.append(' there');\nvar hexHash = spark.end();                      // hex hash\nvar rawHash = spark.end(true);                  // OR raw hash\n```\n\n### Hash a file incrementally\n\nNOTE: If you test the code bellow using the file:// protocol in chrome you must start the browser with -allow-file-access-from-files argument.\n      Please see: http://code.google.com/p/chromium/issues/detail?id=60889\n\n```js\ndocument.getElementById('file').addEventListener('change', function () {\n    var blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice,\n        file = this.files[0],\n        chunkSize = 2097152,                             // Read in chunks of 2MB\n        chunks = Math.ceil(file.size / chunkSize),\n        currentChunk = 0,\n        spark = new SparkMD5.ArrayBuffer(),\n        fileReader = new FileReader();\n\n    fileReader.onload = function (e) {\n        console.log('read chunk nr', currentChunk + 1, 'of', chunks);\n        spark.append(e.target.result);                   // Append array buffer\n        currentChunk++;\n\n        if (currentChunk < chunks) {\n            loadNext();\n        } else {\n            console.log('finished loading');\n            console.info('computed hash', spark.end());  // Compute hash\n        }\n    };\n\n    fileReader.onerror = function () {\n        console.warn('oops, something went wrong.');\n    };\n\n    function loadNext() {\n        var start = currentChunk * chunkSize,\n            end = ((start + chunkSize) >= file.size) ? file.size : start + chunkSize;\n\n        fileReader.readAsArrayBuffer(blobSlice.call(file, start, end));\n    }\n\n    loadNext();\n});\n```\n\nYou can see some more examples in the test folder.\n\n## Documentation\n\n\n### SparkMD5 class\n\n#### SparkMD5#append(str)\n\nAppends a string, encoding it to UTF8 if necessary.\n\n#### SparkMD5#appendBinary(str)\n\nAppends a binary string (e.g.: string returned from the deprecated [readAsBinaryString](https://developer.mozilla.org/en-US/docs/Web/API/FileReader/readAsBinaryString)).\n\n#### SparkMD5#end(raw)\n\nFinishes the computation of the md5, returning the hex result.\nIf `raw` is true, the raw result will be returned instead.\n\n#### SparkMD5#reset()\n\nResets the internal state of the computation.\n\n#### SparkMD5#getState()\n\nReturns an object representing the internal computation state.\nYou can pass this state to setState(). This feature is useful to resume an incremental md5.\n\n#### SparkMD5#setState(state)\n\nSets the internal computation state. See: getState().\n\n#### SparkMD5#destroy()\n\nReleases memory used by the incremental buffer and other additional resources.\n\n#### SparkMD5.hash(str, raw)\n\nHashes a string directly, returning the hex result.\nIf `raw` is true, the raw result will be returned instead.\nNote that this function is `static`.\n\n#### SparkMD5.hashBinary(str, raw)\n\nHashes a binary string directly (e.g.: string returned from the deprecated [readAsBinaryString](https://developer.mozilla.org/en-US/docs/Web/API/FileReader/readAsBinaryString)), returning the hex result.\nIf `raw` is true, the raw result will be returned instead.\nNote that this function is `static`.\n\n\n### SparkMD5.ArrayBuffer class\n\n#### SparkMD5.ArrayBuffer#append(arr)\n\nAppends an array buffer.\n\n#### SparkMD5.ArrayBuffer#end(raw)\n\nFinishes the computation of the md5, returning the hex result.\nIf `raw` is true, the raw result will be returned instead.\n\n#### SparkMD5.ArrayBuffer#reset()\n\nResets the internal state of the computation.\n\n#### SparkMD5.ArrayBuffer#destroy()\n\nReleases memory used by the incremental buffer and other additional resources.\n\n#### SparkMD5.ArrayBuffer#getState()\n\nReturns an object representing the internal computation state.\nYou can pass this state to setState(). This feature is useful to resume an incremental md5.\n\n#### SparkMD5.ArrayBuffer#setState(state)\n\nSets the internal computation state. See: getState().\n\n#### SparkMD5.ArrayBuffer.hash(arr, raw)\n\nHashes an array buffer directly, returning the hex result.\nIf `raw` is true, the raw result will be returned instead.\nNote that this function is `static`.\n\n\n## Credits\n\n[Joseph Myers](http://www.myersdaily.org/joseph/javascript/md5-text.html)\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+ssh://git@github.com/satazor/SparkMD5.git"
  },
  "scripts": {
    "min": "uglifyjs spark-md5.js > spark-md5.min.js",
    "test": "open test/index.html"
  },
  "version": "1.0.1"
}
